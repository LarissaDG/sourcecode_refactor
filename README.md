Estrutura:
* Coleta de dados
* An√°lise explorat√≥ria
* Pr√©-processamento
* Experimento 1
* Experimento 2
* Experimento 3
* Experimento 4
* Experimento 5


Como coletei os dados?
Artigo: https://arxiv.org/abs/2411.08545
Reposit√≥rio: https://github.com/BestiVictory/APDDv2
Modelos: Deepseek janus e APDDv2

An√°lise explorat√≥ria de dados:
An√°lise_Explorat√≥ria_de_Dados_APDDv2.ipynb

Pr√©-processamento


Rodar testes: python3 -m unittest tests/test_sampling.py na pasta: /mnt/c/Users/jggom/Documents/Estudos/Mestrado/sourcecode 
python3 -m visual_sanity_check.visualize_sampling a pasta: /mnt/c/Users/jggom/Documents/Estudos/Mestrado/sourcecode 


#Vamos remodelar com essa estrutura:
* Coleta de dados -> Discursivo
* An√°lise explorat√≥ria -> Notebook
* Pr√©-processamento -> Amostragem/ An√°lise do impacto da amostragem

Parte 1 (APDDv2 viabilidade "Teorica")
* Experimento 1 -> 3.1 -> RQ1: Como a m√©trica se comporta em pinturas humanas vs IA (pequeno vs. grande) do mesmo estilo? 
* Experimento 2 -> 3.2 -> RQ2: Qual o impacto do tamanho do modelo de gera√ß√£o de imagens na qualidade est√©tica das pinturas sint√©ticas?
* Experimento 3 -> 4.1 -> RQ3: Como a m√©trica se comporta em pinturas humanas de estilos diferentes? 
RQ4: As descri√ß√µes de pinturas geradas por IA s√£o expressivas o suficiente para produzir vers√µes sint√©ticas? (Acho que ele queria contrastar o uso do deepseek com a base do portinari que s√£o descri√ß√µes humanas). Era para entrar aqui a an√°lise de prompts
* Experimento 4 -> 4.2

Parte 2 (Experimental "Pr√°tica")
* Experimento 5 -> 5.1 -> RQ5: O quanto a m√©trica √© sens√≠vel a ru√≠do (modifica√ß√µes locais)?
* Experimento 6 -> 5.2 

Organizar o c√≥digo de uma monografia de mestrado exige equil√≠brio entre modularidade (para o desenvolvimento) e reprodutibilidade (para quem vai ler seu trabalho). 
Aqui est√£o as tr√™s estrat√©gias principais para lidar com seus m√∫ltiplos reposit√≥rios:
1. Estrat√©gia de Reposit√≥rio Principal (Recomendado)
Se voc√™ quer algo "bonitinho" como o seu reposit√≥rio do artigo, a melhor abordagem √© criar um "Reposit√≥rio Mestre da Monografia" que conecte tudo. 
Monorepo: Mova os 3 ou 4 reposit√≥rios para pastas dentro de um √∫nico reposit√≥rio novo (ex: /core, /experimentos, /artigo). Isso facilita o versionamento conjunto.
Git Submodules: Se preferir manter os reposit√≥rios separados, use submodules para "espelhar" o conte√∫do deles dentro do reposit√≥rio principal da monografia. 
2. O "Kit de Reprodutibilidade" no README
O examinador ou leitor deve conseguir rodar seu c√≥digo sem sofrer. No reposit√≥rio principal, inclua: 
Script Mestre: Um arquivo (ex: main.py ou run_all.sh) que execute os experimentos sequencialmente.
Gest√£o de Depend√™ncias: Use um arquivo requirements.txt ou ferramentas como Poetry para que o ambiente seja replic√°vel.
README de Alto N√≠vel: Explique a √°rvore de diret√≥rios e onde encontrar cada parte citada no texto da monografia. 
3. Organiza√ß√£o Interna Padr√£o
Para cada reposit√≥rio, siga esta estrutura m√≠nima para manter o padr√£o "bonitinho" do artigo: 
src/: Apenas o c√≥digo-fonte est√°vel.
notebooks/: Para an√°lises explorat√≥rias (limpe os outputs antes de subir).
data/: Dados brutos e processados (ou um README.md explicando como baix√°-los, se forem grandes demais).
docs/: Documenta√ß√£o extra ou figuras geradas. 
Dica de Ouro: Adicione o link do reposit√≥rio final no PDF da sua monografia e, se poss√≠vel, gere um DOI (via Zenodo) para garantir que aquela vers√£o espec√≠fica do c√≥digo seja citada corretamente. 
Voc√™ prefere manter os reposit√≥rios separados (Multi-repo) ou prefere unir tudo em um √∫nico local (Monorepo) para facilitar a entrega final? 


# Automatic Aesthetic Evaluation and Prompt Controllability in Generative Image Models  

This repository contains the code used to conduct experiments and generate results for the paper *Automatic Aesthetic Evaluation and Prompt Controllability in Generative Image Models*, submitted to ICCC 2025.  

## üìå Overview  
The project explores automatic methods for assessing the aesthetic quality of images generated by deep learning models. Additionally, it investigates how prompt variations influence the generated output, analyzing controllability aspects in text-to-image models.  

## üìÅ Repository Structure  
What each file do? Or is here for?

- **.gitgnore**: self-explanatory
- **amostra.py**: Sample the original database so we can work with an expressive part of the hole, without the computational cost associeated with.
- **get_descriptions.py**: Generate the descriptions based on the respective image of the dataset, using Janus 7b. 
- **get_gen_img.py**: Generate the sintetic data based on the generated description in the script above.
- **generate_scores.py**: Evaluate the generated images, using the image, only, to assess the different criteria encompassed by the ArtClip model
- **oficial_script.sh**: Automatize running the scripts
- **manda_email.py**: In oficial_script may need to change the directory. It's used to notify when the script has finished to run.
- **metricas.py**: Sum-up the returned scores in order to produce a statistical analysis.
- **README.md**: self-explanatory 
- **requirements.txt**: self-explanatory

## ‚öôÔ∏è Setup  
To set up the environment, there are some phases you must go through.

### 1) Create a venv.

First you create a enviroment using:

```bash
python3 -m venv venv
```  
Then you create a folder to be your home, where you will install your dependencies:
```bash
mkdir "/minha_home"
```  
Then start your venv using:
```bash
source venv/bin/activate
```  

Set your macros for the path of the created folder above:
```bash
export HOME="/minha_home"
export TRANSFORMERS_CACHE="<path>/minha_home/.cache/huggingface"
export CLIP_CACHE="<path>/minha_home/.cache/clip"
export HF_HOME="<path>/minha_home/.cache/huggingface"
export XDG_CACHE_HOME="/<path>/minha_home/.cache"
export MPLCONFIGDIR="<path>/minha_home/.matplotlib"
```  

Finally copy the present repository with the command below:

```bash
https://github.com/LarissaDG/ICCC.git
```

And install the requirements:

```bash
pip install --no-cache-dir -r "<paht>/requirements.txt" && touch "<paht>/requirements_installed"
```

### 2) Downloading and setting APDDv2
The APDDv2 paper, publicly available at [https://arxiv.org/abs/2411.08545](https://arxiv.org/abs/2411.08545), introduces the Aesthetics of Paintings and Drawings Dataset (APDDv2). This dataset comprises 10,023 images, each annotated with scores across 10 aesthetic attributes and categorized into 24 distinct artistic styles and subject types. These categories encompass various painting techniques, artistic movements, and depicted themes. Additionally, the paper presents ArtCLIP, a pre-trained model specifically designed for aesthetic evaluation of artistic images. ArtCLIP leverages the APDDv2 dataset through a fine-tuned adaptation of the CLIP model, integrating multimodal learning to enhance image aesthetic assessment.

For more details in how to install APDDv2 depend√™ncies check their GitHub: https://github.com/BestiVictory/APDDv2?tab=readme-ov-file

Essentialy you need to follow the steps below:

First, copy the repository:
```bash
git clone https://github.com/BestiVictory/APDDv2?tab=readme-ov-file 
```  

Then download the images. For doing this I suggest the follow commands:
```bash
gdown --id "1ap5dhuEgpPC5PrJozAu2VFmUNIRZrar2" -O "APDDv2images.zip"
```
This folder must be unzip inside the APDDv2 folder created by the git clone step above.

Then you must download the pre-trained models. For this use the command:
```bash
gdown --folder "1AOVKmSqZCW09J_Ypr7KzSYfRxQre-w_m"
```
The models downloaded must be inside the folder: modle_weights. So the folder hierarchy must be similar to:

APDDv2/<br>
‚îú‚îÄ‚îÄ APDDv2images/<br>
‚îÇ   ‚îú‚îÄ‚îÄ image1.png<br>
‚îÇ   ‚îî‚îÄ‚îÄ image2.png<br>
‚îú‚îÄ‚îÄ model_weights/<br>
‚îÇ   ‚îú‚îÄ‚îÄ model_v1.pth<br>
‚îÇ   ‚îî‚îÄ‚îÄ model_v2.pth<br>
‚îî‚îÄ‚îÄ README.md<br>

Now it is time for the settings. First install the requirements:

```bash
pip install --no-cache-dir -r "<path>/APDDv2/requirements.txt" && touch "<path>/requirements_installed_2"
```

Finally test whether the sistem works. In order to do this you must run the scripts:

```bash
python3 "eval.py" || echo "Fail to execute eval.py."
```

```bash
python3 "demo.py" || echo "Fail to execute demo.py."
```

Essentially, both of these files performs an image evaluation using the proposed ArtClip model. The first just return the "general" score, while the second returns all the scores across the 10 aesthetic attributes. However, it worth noting that speacially the model 6 (6.The sense of order_reg_weight--e5-train0.3708-test0.6206_best.pth) was not able to be used, due to model bugs.
Note that you might need to do some adaptations in these scripts in order to acess the right model files, and image files.

### 3) Downloading and setting Janus

For more details in how to install APDDv2 depend√™ncies check their GitHub: https://github.com/deepseek-ai/Janus.git

First, copy the repository:
```bash
git clone https://github.com/deepseek-ai/Janus.git
```  

Now it is time for the settings. First install the requirements:

```bash
pip install -e "<path>/Janus"
``` 
Finally test whether the sistem works. In order to do this you must run the script:

```bash
python3 "<path>/exemple_janus.py" || echo "Erro ao executar exemple_janus.py."
```

## üöÄ Running Experiments  
To reproduce the experiments, execute:  
```bash
sbatch oficial_script.sh
```  

## üìä Results & Analysis  
The results include:  
- Aesthetic score comparisons across different models.  
- Insights into prompt engineering techniques for better controllability.  

## üìú Citation  
If you use this code, please cite our work:

```
@inproceedings{gomide2025iccc,
      title={Automatic Aesthetic Evaluation and Prompt Controllability in Generative Image Models},
      author={Larissa Gomide and Lucas Nascimento Ferreira and Wagner Meira Jr.},
      booktitle={Proceedings of the ICCC 2025},
      year={2025}
    }
```  

Or as indicated by the CITATION.cff

## üìÑ Repository Licenses

This repository contains different types of content, each with its own license. Please follow the instructions below when using any part of the material.

| Content       | License | How to cite / give credit |
|---------------|---------|--------------------------|
| üíª **Software** | ![MIT License](https://img.shields.io/badge/License-MIT-green) | You must retain credit in the code and redistributions. See the [LICENSE](./LICENSE) file for details. |
| üåê **Website**  | ![CC BY 4.0](https://img.shields.io/badge/License-CC--BY%204.0-blue) | Apply CC BY license to text and images; include credits and citation instructions in the site footer. |
| üìä **Dataset**  | ![CC BY 4.0](https://img.shields.io/badge/License-CC--BY%204.0-blue) | Include a `LICENSE` file and a `README` with clear citation instructions and bibliographic references. |


## üì¨ Contact  
For any questions or collaborations, feel free to reach out:  
üìß lainterlocucao@gmail.com

